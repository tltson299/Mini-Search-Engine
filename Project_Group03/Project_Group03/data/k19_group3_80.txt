Computer science is the study of computation and information.[1][2] Computer science deals with theory of computation, algorithms, computational problems and the design of computer systems hardware, software and applications.[3][4] Computer science addresses both human-made and natural information processes, such as communication, control, perception, learning and intelligence especially in human-made computing systems and machines.[5][6][7]

Its fields can be divided into theoretical and practical disciplines. For example computational complexity theory describes the amount of resources required to solve computational problems, while computer graphics and computational geometry emphasizes more specific applications. Algorithmics have been called the heart of computer science.[8] Programming language theory considers approaches to the description of computational processes, while software engineering involves the use of programming languages and complex systems. Computer architecture and computer engineering deals with construction of computer components and computer-controlled equipment.[5][9] Human–computer interaction considers the challenges in making computers useful, usable, and accessible. Artificial intelligence aims to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, motion planning, learning, and communication found in humans and animals. According to Peter Denning, the fundamental question underlying computer science is, What can be automated?[10][5]


Contents
1	History
2	Etymology
3	Philosophy
4	Fields
4.1	Theoretical computer science
4.1.1	Theory of computation
4.1.2	Information and coding theory
4.1.3	Data structures and algorithms
4.1.4	Programming language theory
4.1.5	Formal methods
4.2	Computer systems
4.2.1	Computer architecture and computer engineering
4.2.2	Computer performance analysis
4.2.3	Concurrent, parallel and distributed systems
4.2.4	Computer networks
4.2.5	Computer security and cryptography
4.2.6	Databases
4.3	Computer applications
4.3.1	Computer graphics and visualization
4.3.2	Human–computer interaction
4.3.3	Scientific computing and simulation
4.3.4	Artificial intelligence
4.4	Software engineering
5	Discoveries
6	Programming paradigms
7	Academia
8	Education
9	See also
10	Notes
11	References
12	Further reading
12.1	Overview
12.2	Selected literature
12.3	Articles
12.4	Curriculum and classification
13	External links
13.1	Bibliography and academic search engines
13.2	Professional organizations
13.3	Misc
History
Main article: History of computer science
History of computing
Hardware
Hardware before 1960Hardware 1960s to present
Software
SoftwareUnixFree software and open-source software
Computer science
Artificial intelligenceCompiler constructionComputer scienceOperating systemsProgramming languagesProminent pioneersSoftware engineering
Modern concepts
General-purpose CPUsGraphical user interfaceInternetLaptopsPersonal computersVideo gamesWorld Wide Web
By country
BulgariaPolandRomaniaSoviet BlocSoviet UnionYugoslavia
Timeline of computing
before 19501950–19791980–19891990–19992000–20092010–20192020–2029more timelines ...
Glossary of computer science
Category Category
vte

Charles Babbage, sometimes referred to as the "father of computing".[11]

Ada Lovelace published the first algorithm intended for processing on a computer.[12]
The earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.
Wilhelm Schickard designed and constructed the first working mechanical calculator in 1623.[13] In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner.[14] Leibniz may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry